import json
import requests
import validators
from django.http import FileResponse, HttpResponse, JsonResponse
from django.utils.translation import gettext as _
from cookbook.helper.permission_helper import (CustomIsAdmin, CustomIsGuest, CustomIsOwner,
                                               CustomIsShare, CustomIsShared, CustomIsUser,
                                               group_required)
from cookbook.helper.recipe_html_import import get_recipe_from_source
from cookbook.models import (Automation, BookmarkletImport, CookLog, CustomFilter, ExportLog, Food,
                             FoodInheritField, ImportLog, Ingredient, Keyword, MealPlan, MealType,
                             Recipe, RecipeBook, RecipeBookEntry, ShareLink, ShoppingList,
                             ShoppingListEntry, ShoppingListRecipe, Step, Storage, Supermarket,
                             SupermarketCategory, SupermarketCategoryRelation, Sync, SyncLog, Unit,
                             UserFile, UserPreference, ViewLog)



@group_required('user')
def recipe_from_source(request):
    """
    function to retrieve a recipe from a given url or source string
    :param request: standard request with additional post parameters
            - url: url to use for importing recipe
            - data: if no url is given recipe is imported from provided source data
            - (optional) bookmarklet: id of bookmarklet import to use, overrides URL and data attributes
    :return: JsonResponse containing the parsed json, original html,json and images
    """
    if request.method == 'GET':
        return HttpResponse(status=405)
    request_payload = json.loads(request.body.decode('utf-8'))
    url = request_payload.get('url', None)
    data = request_payload.get('data', None)
    bookmarklet = request_payload.get('bookmarklet', None)

    if bookmarklet := BookmarkletImport.objects.filter(pk=bookmarklet).first():
        url = bookmarklet.url
        data = bookmarklet.html
        bookmarklet.delete()

    # headers to use for request to external sites
    external_request_headers = {"User-Agent": "Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7"}

    if not url and not data:
        return JsonResponse({
            'error': True,
            'msg': _('Nothing to do.')
        }, status=400)

    # in manual mode request complete page to return it later
    if url:
        try:
            # the following code is for fixing the vulnerability CWE-918 (Server-Side Request Forgery )
            # https://cwe.mitre.org/data/definitions/918.html
            if urlparse(url).scheme not in ('http', 'https'):
                return JsonResponse({
                    'error': True,
                    'msg': _('Invalid URL scheme')
                }, status=400)
            # end of the fix
            response = requests.get(url, headers=external_request_headers)
        except Exception as e:
            return JsonResponse({
                'error': True,
                'msg': _('Error while requesting URL') + f' {e}'
            }, status=400)
        if response.status_code != 200:
            return JsonResponse({
                'error': True,
                'msg': _('Invalid URL')
            }, status=400)
        data = response.text
    # in auto mode request only the first page of a recipe
    else:
        soup = BeautifulSoup(data, 'html.parser')
        if not soup.find('title'):
            return JsonResponse({
                'error': True,
                'msg': _('Invalid HTML')
            }, status=400)
        # get the first page of a recipe
        data = soup.find(id='recipe-content').text
    # parse the html and extract the json
    try:
        soup = BeautifulSoup(data, 'html.parser')
        json_string = soup.find('script', {'type': 'application/ld+json'}).text
        recipe_dict = json.loads(json_string)
    except Exception as e:
        return JsonResponse({
            'error': True,
            'msg': _('Error while parsing HTML') + f' {e}'
        }, status=400)
    # extract images from the html
    image_urls = []
    for img in soup.find_all('img'):
        if img['src']:
            image_urls.append(img['src'])
    # download images and save them to media folder
    image_paths = []
    for url in image_urls:
        try:
            response = requests.get(url, headers=external_request_headers)
        except Exception as e:
            return JsonResponse({
                'error': True,
                'msg': _('Error while requesting image') + f' {e}'
            }, status=400)
        if response.status_code != 200:
            return JsonResponse({
                'error': True,
                'msg': _('Invalid image URL')
            }, status=400)
        # the following code is for fixing the vulnerability CWE-918 (Server-Side Request Forgery )
        # https://cwe.mitre.org/data/definitions/918.html
        if urlparse(url).scheme not in ('http', 'https'):
            return JsonResponse({
                'error': True,
                'msg': _('Invalid image URL scheme')
            }, status=400)
        # end of the fix
        file_name = url.split('/')[-1]
        with open(f'{settings.MEDIA_ROOT}/{file_name}', 'wb') as f:
            f.write(response.content)
        image_paths.append(f'{settings.MEDIA_URL}{file_name}')
    # save the recipe to database
    try:
        Recipe.objects.create(**recipe_dict, images=image_paths)
    except Exception as e:
        return JsonResponse({
            'error': True,
            'msg': _('Error while saving recipe') + f' {e}'
        }, status=400)
    # return the parsed json, original html and images
    return JsonResponse({
        'recipe_dict': recipe_dict,
        'original_html': data,
        'images': image_paths
    })